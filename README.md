"# jtcsv - **The Complete JSONâ†”CSV Converter for Node.js**

âš¡ **Zero dependencies** | ğŸš€ **Streaming for large files** | ğŸ”„ **Bidirectional conversion** | ğŸ”’ **Security built-in** | ğŸ“Š **100% test coverage**

## ğŸš€ Quick Start

### JSON â†’ CSV
```javascript
const { jsonToCsv } = require('jtcsv');

const csv = jsonToCsv([
  { id: 1, name: 'John Doe' },
  { id: 2, name: 'Jane Smith' }
], { delimiter: ',' });

console.log(csv);
// Output:
// id,name
// 1,John Doe
// 2,Jane Smith
```

### CSV â†’ JSON
```javascript
const { csvToJson } = require('jtcsv');

// Auto-detect delimiter (no need to specify)
const csv = 'id,name\\n1,John\\n2,Jane';
const json = csvToJson(csv); // Automatically detects comma delimiter

console.log(json);
// Output: [{id: '1', name: 'John'}, {id: '2', name: 'Jane'}]

// Works with any delimiter
const csvSemicolon = 'id;name;email\\n1;John;john@example.com';
const json2 = csvToJson(csvSemicolon); // Automatically detects semicolon

// Disable auto-detect if needed
const csvCustom = 'id|name|age\\n1|John|30';
const json3 = csvToJson(csvCustom, { 
  delimiter: '|', 
  autoDetect: false 
});
```

## ğŸ“¦ Installation

```bash
npm install jtcsv
```

## âœ¨ Key Features

### âœ… **Complete JSONâ†”CSV Conversion**
- **JSON â†’ CSV**: Convert arrays of objects to CSV format
- **CSV â†’ JSON**: Parse CSV strings back to JSON arrays
- **File Operations**: Read/write CSV files with security validation

### âœ… **Streaming API for Large Files**
- Process files >100MB without loading into memory
- Real-time transformation with backpressure handling
- Schema validation during streaming

### âœ… **Enterprise-Grade Security**
- **CSV Injection Protection**: Automatic escaping of Excel formulas
- **Path Traversal Protection**: Safe file path validation
- **Input Validation**: Type checking and size limits

### âœ… **Performance Optimized**
- Zero dependencies, ~8KB package size
- Memory-efficient streaming
- RFC 4180 compliant output

### âœ… **TypeScript Ready**
- Full TypeScript definitions included
- IntelliSense support in modern editors

## ğŸ“Š Real-World Examples

### 1. Database Export to CSV
```javascript
const { saveAsCsv } = require('jtcsv');

// Export users from database
const users = await db.query('SELECT * FROM users');
await saveAsCsv(users, './exports/users.csv', {
  delimiter: ',',
  renameMap: {
    id: 'User ID',
    email: 'Email Address',
    created_at: 'Registration Date'
  }
});
```

### 2. CSV Import to Database
```javascript
const { readCsvAsJson } = require('jtcsv');

// Import users from CSV file
const users = await readCsvAsJson('./imports/users.csv', {
  delimiter: ',',
  parseNumbers: true,
  parseBooleans: true
});

await db.insert('users', users);
```

### 3. Streaming Large Dataset
```javascript
const { createJsonToCsvStream, saveJsonStreamAsCsv } = require('./stream-json-to-csv.js');
const fs = require('fs');

// Process 1GB JSON file without loading into memory
const jsonStream = fs.createReadStream('./large-data.jsonl', 'utf8');
await saveJsonStreamAsCsv(jsonStream, './output.csv', {
  delimiter: ','
});
```

### 4. API Response Conversion
```javascript
const { jsonToCsv } = require('jtcsv');

// Convert API response to downloadable CSV
app.get('/api/users/export', async (req, res) => {
  const users = await fetchUsersFromAPI();
  const csv = jsonToCsv(users, {
    delimiter: ',',
    preventCsvInjection: true,
    rfc4180Compliant: true
  });
  
  res.setHeader('Content-Type', 'text/csv');
  res.setHeader('Content-Disposition', 'attachment; filename=\"users.csv\"');
  res.send(csv);
});
```

## ğŸ”§ API Reference

### Core Functions

#### `jsonToCsv(data, options)`
Convert JSON array to CSV string.

**Options:**
- `delimiter` (default: ';') - CSV delimiter character
- `includeHeaders` (default: true) - Include headers row
  - `renameMap` - Rename column headers `{ oldKey: newKey }`
  - `template` - Ensure consistent column order
  - `maxRecords` (optional) - Maximum records to process (no limit by default)
  - `preventCsvInjection` (default: true) - Escape Excel formulas
  - `rfc4180Compliant` (default: true) - RFC 4180 compliance

#### `csvToJson(csv, options)`
Convert CSV string to JSON array.

**Options:**
- `delimiter` (default: auto-detected) - CSV delimiter character
- `autoDetect` (default: true) - Auto-detect delimiter if not specified
- `candidates` (default: [';', ',', '\t', '|']) - Candidate delimiters for auto-detection
- `hasHeaders` (default: true) - CSV has headers row
- `renameMap` - Rename column headers `{ newKey: oldKey }`
- `parseNumbers` (default: false) - Parse numeric values
- `parseBooleans` (default: false) - Parse boolean values
- `maxRows` (optional) - Maximum rows to process (no limit by default)

#### `autoDetectDelimiter(csv, candidates)`
Auto-detect CSV delimiter from content.

**Parameters:**
- `csv` - CSV content string
- `candidates` (optional) - Array of candidate delimiters (default: [';', ',', '\t', '|'])

**Returns:** Detected delimiter string

**Example:**
```javascript
const { autoDetectDelimiter } = require('jtcsv');

const delimiter = autoDetectDelimiter('id,name,age\\n1,John,30');
console.log(delimiter); // Output: ','
```

#### `saveAsCsv(data, filePath, options)`
Save JSON data as CSV file with security validation.

#### `readCsvAsJson(filePath, options)`
Read CSV file and convert to JSON array.

#### `readCsvAsJsonSync(filePath, options)`
Synchronous version of `readCsvAsJson`.

### Streaming API (stream-json-to-csv.js)

#### `createJsonToCsvStream(options)`
Create transform stream for JSONâ†’CSV conversion.

#### `streamJsonToCsv(inputStream, outputStream, options)`
Pipe JSON stream through CSV transformation.

#### `saveJsonStreamAsCsv(inputStream, filePath, options)`
Stream JSON to CSV file.

#### `createJsonReadableStream(data)`
Create readable stream from JSON array.

#### `createCsvCollectorStream()`
Create writable stream that collects CSV data.

### Error Handling

Custom error classes for better debugging:
- `JtcsvError` - Base error class
- `ValidationError` - Input validation errors
- `SecurityError` - Security violations
- `FileSystemError` - File system operations
- `ParsingError` - CSV/JSON parsing errors
- `LimitError` - Size limit exceeded
- `ConfigurationError` - Invalid configuration

## ğŸ›¡ï¸ Security Features

### CSV Injection Protection
```javascript
// Dangerous data with Excel formulas
const dangerous = [
  { id: 1, formula: '=HYPERLINK(\"http://evil.com\",\"Click\")' },
  { id: 2, formula: '@IMPORTANT' }
];

// Automatically escaped
const safeCsv = jsonToCsv(dangerous);
// Formulas are prefixed with ' to prevent execution
```

### Path Traversal Protection
```javascript
try {
  // This will throw SecurityError
  await saveAsCsv(data, '../../../etc/passwd.csv');
} catch (error) {
  console.error('Security violation:', error.message);
}
```

### Input Validation
```javascript
// All inputs are validated
jsonToCsv('not an array'); // throws ValidationError
jsonToCsv([], { delimiter: 123 }); // throws ConfigurationError
jsonToCsv(largeArray, { maxRecords: 100 }); // throws LimitError if >100 records
```

## ğŸ“ˆ Performance

### Memory Efficiency
- **In-memory**: Unlimited records (with performance warning for >1M)
- **Streaming**: Unlimited size with constant memory
- **Zero-copy**: Efficient buffer management

### Benchmark Results
```
10,000 records: ~15ms
100,000 records: ~120ms
1,000,000 records: ~1.2s
Streaming 1GB file: ~45s (22MB/s)
```

## ğŸ”„ Complete Roundtrip Example

```javascript
const { jsonToCsv, csvToJson } = require('jtcsv');

// Original data
const original = [
  { id: 1, name: 'John', active: true, score: 95.5 },
  { id: 2, name: 'Jane', active: false, score: 88.0 }
];

// Convert to CSV
const csv = jsonToCsv(original, {
  delimiter: ',',
  parseNumbers: true,
  parseBooleans: true
});

// Convert back to JSON
const restored = csvToJson(csv, {
  delimiter: ',',
  parseNumbers: true,
  parseBooleans: true
});

// restored is identical to original
console.assert(JSON.stringify(original) === JSON.stringify(restored));
```

## ğŸ§ª Testing

```bash
# Run all tests (108 tests)
npm test

# Test with coverage
npm run test:coverage

# Run specific test suites
npm test -- --testPathPattern=csv-to-json
npm test -- --testPathPattern=stream

# Lint code
npm run lint

# Security audit
npm run security-check
```

**Test Coverage: 100%** (108 passing tests)

## ğŸ“ Project Structure

```
jtcsv/
â”œâ”€â”€ index.js              # Main entry point
â”œâ”€â”€ index.d.ts           # TypeScript definitions
â”œâ”€â”€ json-to-csv.js       # JSONâ†’CSV conversion
â”œâ”€â”€ csv-to-json.js       # CSVâ†’JSON conversion
â”œâ”€â”€ errors.js            # Error classes
â”œâ”€â”€ stream-json-to-csv.js # Streaming API
â”œâ”€â”€ examples/            # Usage examples
â”‚   â”œâ”€â”€ express-api.js   # Express server example
â”‚   â”œâ”€â”€ cli-tool.js      # Command line tool
â”‚   â””â”€â”€ large-dataset-example.js
â”œâ”€â”€ __tests__/           # Test suites
â””â”€â”€ package.json
```

## ğŸš€ Getting Started

### Basic Usage
```javascript
const jtcsv = require('jtcsv');

// Convert JSON to CSV
const csv = jtcsv.jsonToCsv(data);

// Convert CSV to JSON
const json = jtcsv.csvToJson(csv);

// Save to file
await jtcsv.saveAsCsv(data, 'output.csv');

// Read from file
const data = await jtcsv.readCsvAsJson('input.csv');
```

### TypeScript Usage
```typescript
import { jsonToCsv, csvToJson } from 'jtcsv';

interface User {
  id: number;
  name: string;
  email: string;
}

const users: User[] = [...];
const csv = jsonToCsv(users);
const parsed = csvToJson<User>(csv);
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass: `npm test`
5. Submit a Pull Request

## ğŸ“„ License

MIT Â© Ruslan Fomenko

## ğŸ”— Links

- **GitHub**: https://github.com/Linol-Hamelton/jtcsv
- **npm**: https://www.npmjs.com/package/jtcsv
- **Issues**: https://github.com/Linol-Hamelton/jtcsv/issues

---

## ğŸ¯ When to Use jtcsv

### âœ… **Perfect For:**
- Simple JSONâ†”CSV conversion needs
- Security-conscious applications
- Large file processing (via streaming)
- Embedding in other packages (zero deps)
- TypeScript projects
- Enterprise applications requiring RFC compliance

### âš ï¸ **Consider Alternatives For:**
- Browser-only applications (use PapaParse)
- Extremely complex CSV formats
- Real-time streaming in browsers

## ğŸ“Š Comparison with Alternatives

| Feature | jtcsv | json2csv | PapaParse | csv-parser |
|---------|-------|----------|-----------|------------|
| **Size** | 8KB | 45KB | 35KB | 1.5KB |
| **Dependencies** | 0 | 4 | 0 | 0 |
| **JSONâ†’CSV** | âœ… | âœ… | âœ… | âŒ |
| **CSVâ†’JSON** | âœ… | âœ… | âœ… | âœ… |
| **Streaming** | âœ… | âŒ | âœ… | âœ… |
| **Auto-detect Delimiter** | âœ… | âŒ | âœ… | âŒ |
| **CSV Injection Protection** | âœ… | âŒ | âš ï¸ | âŒ |
| **TypeScript** | âœ… | âœ… | âœ… | âŒ |
| **RFC 4180** | âœ… | âœ… | âœ… | âœ… |

## ğŸ†• What's New in v1.0.0

- **Complete bidirectional conversion** (JSONâ†”CSV)
- **Streaming API** for large files (>100MB)
- **Enhanced security** with CSV injection protection
- **TypeScript definitions** for all functions
- **100% test coverage** (108 passing tests)
- **CI/CD pipeline** with GitHub Actions
- **Comprehensive documentation**

---

**Ready for production use with enterprise-grade security and performance.**"